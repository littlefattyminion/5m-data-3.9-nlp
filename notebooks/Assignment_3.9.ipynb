{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6cd5f2",
   "metadata": {},
   "source": [
    "### Text Classification for Spam Detection\n",
    "\n",
    "In this assignment, you will build a text classification model using Naive Bayes to classify SMS messages as spam or ham (non-spam). You will implement text preprocessing techniques and use the Vector Space Model (TF-IDF) to represent the text data.\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "You will be using the SMS Spam Collection dataset, which contains a set of SMS messages that have been labeled as either spam or ham (legitimate). This dataset is available through several Python libraries or can be downloaded directly.\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "1. **Text Preprocessing**:\n",
    "\n",
    "   - Load the dataset\n",
    "   - Implement tokenization\n",
    "   - Apply stemming or lemmatization\n",
    "   - Remove stopwords\n",
    "\n",
    "2. **Feature Extraction**:\n",
    "\n",
    "   - Use TF-IDF vectorization to convert the text data into numerical features\n",
    "   - Explore the most important features for spam and ham categories\n",
    "\n",
    "3. **Classification**:\n",
    "\n",
    "   - Split the data into training and testing sets\n",
    "   - Train a Multinomial Naive Bayes classifier\n",
    "   - Evaluate the model using appropriate metrics (accuracy, precision, recall, F1-score)\n",
    "   - Create a confusion matrix to visualize the results\n",
    "\n",
    "4. **Analysis**:\n",
    "   - Analyze false positives and false negatives\n",
    "   - Identify characteristics of messages that are frequently misclassified\n",
    "   - Suggest improvements to your model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f40d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message\n",
      "0   ham                      Ok lar... Joking wif u oni...\n",
      "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "2   ham  U dun say so early hor... U c already then say...\n",
      "3   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "4  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "label\n",
      "ham     4824\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "#import necessary libraries for text processing and model building\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Load the SMS Spam Collection dataset\n",
    "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
    "urllib.request.urlretrieve(url, \"sms.tsv\")\n",
    "sms_data = pd.read_csv('sms.tsv', sep='\\t')\n",
    "sms_data.columns = [\"label\", \"message\"]\n",
    "print(sms_data.head())\n",
    "\n",
    "\n",
    "# Check data distribution\n",
    "print(sms_data['label'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fc472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/smapgal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/smapgal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/smapgal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement text preprocessing\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Lemmatization (optional alternative to Stemming)\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ad53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tools\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Lemmatizer (optional alternative to Stemming)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove numbers and punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 3. Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # 5. Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # 6. Lemmatization \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # 7. Join back to string\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7a4eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              message  \\\n",
      "0                       Ok lar... Joking wif u oni...   \n",
      "1   Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "2   U dun say so early hor... U c already then say...   \n",
      "3   Nah I don't think he goes to usf, he lives aro...   \n",
      "4   FreeMsg Hey there darling it's been 3 week's n...   \n",
      "5   Even my brother is not like to speak with me. ...   \n",
      "6   As per your request 'Melle Melle (Oru Minnamin...   \n",
      "7   WINNER!! As a valued network customer you have...   \n",
      "8   Had your mobile 11 months or more? U R entitle...   \n",
      "9   I'm gonna be home soon and i don't want to tal...   \n",
      "10  SIX chances to win CASH! From 100 to 20,000 po...   \n",
      "11  URGENT! You have won a 1 week FREE membership ...   \n",
      "12  I've been searching for the right words to tha...   \n",
      "13                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
      "14  XXXMobileMovieClub: To use your credit, click ...   \n",
      "15                         Oh k...i'm watching here:)   \n",
      "16  Eh u remember how 2 spell his name... Yes i di...   \n",
      "17  Fine if thats the way u feel. Thats the way ...   \n",
      "18  England v Macedonia - dont miss the goals/team...   \n",
      "19          Is that seriously how you spell his name?   \n",
      "\n",
      "                                        clean_message  \n",
      "0                               ok lar joke wif u oni  \n",
      "1   free entri wkli comp win fa cup final tkt st m...  \n",
      "2                 u dun say earli hor u c alreadi say  \n",
      "3           nah dont think goe usf live around though  \n",
      "4   freemsg hey darl week word back id like fun st...  \n",
      "5       even brother like speak treat like aid patent  \n",
      "6   per request mell mell oru minnaminungint nurun...  \n",
      "7   winner valu network custom select receivea pri...  \n",
      "8   mobil month u r entitl updat latest colour mob...  \n",
      "9   im gon na home soon dont want talk stuff anymo...  \n",
      "10  six chanc win cash pound txt csh send cost pda...  \n",
      "11  urgent week free membership prize jackpot txt ...  \n",
      "12  ive search right word thank breather promis wo...  \n",
      "13                                        date sunday  \n",
      "14  xxxmobilemovieclub use credit click wap link n...  \n",
      "15                                       oh kim watch  \n",
      "16     eh u rememb spell name ye v naughti make v wet  \n",
      "17               fine that way u feel that way gota b  \n",
      "18  england v macedonia dont miss goalsteam news t...  \n",
      "19                                 serious spell name  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Apply Preprocessing to Dataset\n",
    "sms_data['clean_message'] = sms_data['message'].apply(preprocess_text)\n",
    "\n",
    "print(sms_data[['message', 'clean_message']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ef954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply TF-IDF vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d5712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5571, 5000)\n"
     ]
    }
   ],
   "source": [
    "#create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,     # limit vocabulary size\n",
    "    ngram_range=(1,2),     # use unigrams + bigrams\n",
    "    min_df=2               # ignore rare words\n",
    ")\n",
    "X = tfidf.fit_transform(sms_data['clean_message'])\n",
    "y = sms_data['label'].str.strip\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Split data into training and testing sets\n",
    "\n",
    "#Convert the labels to binary values\n",
    "y = sms_data['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    X, y, test_size=0.2, random_state=42\n",
    "#)\n",
    "\n",
    "# To redo the train-test split with indices\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, sms_data.index, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faad5416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train a Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72aa4ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9775784753363229\n",
      "\n",
      "Confusion Matrix:\n",
      " [[955   0]\n",
      " [ 25 135]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       955\n",
      "           1       1.00      0.84      0.92       160\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluate the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced97eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze misclassifications\n",
    "\n",
    "# Identify misclassified samples\n",
    "# Create a DataFrame for comparison\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'message': sms_data.loc[idx_test, 'message'].values,\n",
    "    'actual': y_test.values,\n",
    "    'predicted': y_pred\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7416ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified messages: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ringtoneking 84484</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Can U get 2 phone NOW? I wanna chat 2 set up m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Free-message: Jamster!Get the crazy frog sound...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Ever thought about living a good life with a p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Ur balance is now £600. Next question: Complet...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               message  actual  predicted\n",
       "41                                  ringtoneking 84484       1          0\n",
       "52   Can U get 2 phone NOW? I wanna chat 2 set up m...       1          0\n",
       "59   Free-message: Jamster!Get the crazy frog sound...       1          0\n",
       "148  Ever thought about living a good life with a p...       1          0\n",
       "245  Ur balance is now £600. Next question: Complet...       1          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract misclassified samples\n",
    "misclassified = results[results['actual'] != results['predicted']]\n",
    "\n",
    "print(\"Number of misclassified messages:\", len(misclassified))\n",
    "misclassified.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63b63558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [message, actual, predicted]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate false positives \n",
    "\n",
    "false_positive = results[(results['actual'] == 0) & (results['predicted'] == 1)]\n",
    "print(\"False Positives:\", len(false_positive))\n",
    "false_positive.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6079e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negatives: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ringtoneking 84484</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Can U get 2 phone NOW? I wanna chat 2 set up m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Free-message: Jamster!Get the crazy frog sound...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Ever thought about living a good life with a p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Ur balance is now £600. Next question: Complet...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               message  actual  predicted\n",
       "41                                  ringtoneking 84484       1          0\n",
       "52   Can U get 2 phone NOW? I wanna chat 2 set up m...       1          0\n",
       "59   Free-message: Jamster!Get the crazy frog sound...       1          0\n",
       "148  Ever thought about living a good life with a p...       1          0\n",
       "245  Ur balance is now £600. Next question: Complet...       1          0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#false negatives\n",
    "false_negative = results[(results['actual'] == 1) & (results['predicted'] == 0)]\n",
    "print(\"False Negatives:\", len(false_negative))\n",
    "false_negative.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7d4bb",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The model produced zero false positives, meaning no legitimate messages were incorrectly flagged as spam. However, there were 25 false negatives, indicating that some spam messages were misclassified as ham. This suggests the model is conservative and prioritizes precision over recall. While this reduces the risk of blocking valid messages, it allows some spam messages to pass through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bea114",
   "metadata": {},
   "source": [
    "# To improve model\n",
    "\n",
    "1) Tune TD-IDF features by increasing from 5000 to 7000\n",
    "2) Tune Naive Bayes Smoothing (alpha) and Smaller alpha → model is more sensitive to rare words.\n",
    "3) Adjust Prediction Threshold - Lower Threshold can catch more spam however maybe increase false positive\n",
    "4) Increase features - Increase message length and special characters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
